
\section[API Implementation]{API Implementation}\label{sec:api}
As explained in the section about the architecture ~\ref{subsec:apiArchitecture}, the \gls{API} has a division by modules, and each module follows a predefined structure, with a controller layer, responsible for receiving \gls{HTTP} requests, a service layer, responsible for handling data and business rules, and a repository layer, responsible for managing access to the database of that module.

In addition, the \gls{API} also has parts that are common to all modules. The infrastructure that has the function of providing a database access interface, a web socket message sending access interface, authentication means, and the thread manager. The common codes, which store constants, common functions that need to be standardized, and data models.
Therefore, this section will address each of these parts, first going through the common parts of the system and then showing how a complete module was developed.

\subsection{Initialization}\label{subsec:main}
The system initialization occurs through the \texttt{main.py} file, which serves as the entry point to initialize the \gls{API} and the data processing module.

The \texttt{FastAPI} library \cite{fastapiDocs} is used to create the main application, here referred to as \texttt{app}. The \texttt{CORSMiddleware} middleware is added to the \texttt{FastAPI} application, allowing for comprehensive \gls{CORS} (Cross-Origin Resource Sharing) configuration. This configuration allows the \gls{API} to be accessed from different origins.

The import of the \texttt{API\_data\_layer} module not only incorporates the routes related to this module, but also initializes the data receiving module. This implies that the initialization of this module occurs simultaneously with the loading of the \gls{API}, but on a separate thread, as detailed in ~\ref{sec:ImplModuloProcessamento}.

For metadata management, an instance of the \texttt{MetadataRepository} is created during initialization. This component is essential for loading the metadata that are used in different parts of the system, such as constants and alarm parameters.

The \gls{API} routes are then included in the main application through the \texttt{include\_router} method for different modules, such as authentication, API analysis, data layer, notifications, and users.

Additionally, the WebSocket is mounted at the root of the application through the \texttt{socketio\_app} object, enabling real-time communication between the server and the clients. The implementation of the websocket connection can be seen in ~\ref{subsubsec:WebSocketImplement}.

The execution of the file concludes with the initialization of the \texttt{Uvicorn} server \cite{uvicornOfficialDocs}, setting the host and port for listening. \texttt{Uvicorn} is an \gls{ASGI} server that serves as the interface between the application code and the web server. It is responsible for hosting the \texttt{FastAPI} application and listening for incoming connections on the specified host and port. The choice of this server was based on the recommendation from the FastAPI documentation \cite{fastapiTutorial}.

\begin{verbatim}
from fastapi import FastAPI
import uvicorn
from fastapi.middleware.cors import CORSMiddleware
from src.infrastructure.database.metadata.metadata_repository import (
MetadataRepository)
from src.modules.api_analytics import api_analytics_router
from src.modules.api_data_layer import api_data_layer_router
from src.modules.notifications import notification_module_router
from src.modules.user import user_module_router, auth_router
from src.infrastructure.websocket import socketio_app
from src.infrastructure.websocket import socket_dispacher
from dotenv import load_dotenv

load_dotenv()
MetadataRepository()
socket_dispacher
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)
@app.get("/")
async def health_check():
    return {
        "Status":"OK",
        "Message":"Access /docs for more information"    
    }
app.include_router(auth_router)
app.include_router(api_analytics_router)
app.include_router(api_data_layer_router)
app.include_router(notification_module_router)
app.include_router(user_module_router)

app.mount("/",socketio_app)

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)
\end{verbatim}

\subsection{Infrastructure}\label{subsec:infra}

The infrastructure is composed of 4 sub-modules, Authentication, WebSocket, Database Connection, and Thread Management.

\subsubsection{Authentication}\label{subsubsec:auth}
The system's authentication implementation was based on the official FastAPI documentation \cite{fastapiSecurity}, therefore a token-based approach was adopted using \gls{JWT}. The \gls{JWT} is a widely accepted standard for securely transmitting information between parties. The structure of a \gls{JWT} is encoded and can be verified to ensure that the data has not been altered during transmission.

The entry point for authentication is the \texttt{o\_auth2\_password\_bearer}, an instance of OAuth2PasswordBearer that is designed to obtain the token from the request header. The \texttt{auth\_middleware} method was defined as an asynchronous middleware, which depends on this bearer token. This middleware is used in the controllers to verify whether the received request has permission to access the information or not.

Within this middleware, the \texttt{decode\_jwt\_token} function is invoked to decode and validate the provided \gls{JWT} token.

\begin{verbatim}
o_auth2_password_bearer = OAuth2PasswordBearer(tokenUrl="/user/login")

async def auth_middleware(token:str = Depends(o_auth2_password_bearer))-> TokenPayload:
    try:
        result = decode_jwt_token(token)
        if result.status:
            return result.data
        else:
            raise HTTPException(status_code=401, detail=result.exception.message)
    except JWSError as jwt_err:
        print(jwt_err)
        raise HTTPException(status_code=401, detail=Unauthorized().message)
\end{verbatim}

The function \texttt{decode\_jwt\_token} receives a token as an argument and attempts to decode it using the specified secret key and algorithm. If the token is successfully decoded and is of the type "\texttt{access\_token}". Otherwise, different types of exceptions can be raised, for example, if the token has expired or if there is some error in the \gls{JWT} operations.

\begin{verbatim}
def decode_jwt_token(token:str)->Result[TokenPayload|None]:
    try:
        token_dict = jwt.decode(token,key=SECRET_KEY, algorithms=ALGORITHM)
        if token_dict["type"] != "access_token":
            return Result(status=False, exception=WrongTokenType(), data=None)
        token_payload = TokenPayload(**token_dict)
        return Result(status=True, data=token_payload, exception=None)
    
    except ExpiredSignatureError as invalid_token:
        return Result(status=False, exception=Unauthorized(exception=invalid_token), data=None)

    except (JWSError, JOSEError, JWTError, JWEError) as ex:
        return Result(status=False, exception=GenericException(message="Authorization error!",exception=ex), data=None)

    except Exception as ex:
        print(ex)
        raise ex
\end{verbatim}

The model class for the token payload is as follows:
\begin{verbatim}
class TokenPayload(BaseModel):
    name:str
    exp:int|None = None
    sub:str|None = None
    user_id:str
    type:str = "access_token"
\end{verbatim}

The \texttt{AuthService} class is where the main authentication logic is implemented. This class follows the \textit{Singleton} pattern to ensure that only one instance is created and used throughout the program execution.

Within \texttt{AuthService}, the \texttt{verify\_password} method is used to check if a provided password matches an encrypted password, while the \texttt{hash\_password} is responsible for encrypting a provided password.

The \texttt{create\_user\_tokens} method generates a pair of tokens (access and refresh) for a user, where the access token is valid for 4 hours and the refresh token for 168 hours. The refresh token is especially important to allow users to obtain new access tokens without having to enter their credentials again. If the access token expires, the refresh token can be used to obtain a new pair of tokens, using the \texttt{get\_new\_user\_tokens} method. It is important to note that the frontend does not yet make use of the refresh token, leaving this functionality for a future implementation.

\begin{verbatim}
class AuthService(metaclass=Singleton):
    def __init__(self):
        self.__database__ = MongoDB()
        self.__user_repository = UserRepository()

        self.__ACCESS_TOKEN_EXPIRE_HOURS__ = 4
        self.__REFRESH_TOKEN_EXPIRE_HOURS__ = 168
        self.__SECRET_KEY__ = SECRET_KEY
        self.__ALGORITHM__ = ALGORITHM
        self.__pwd_context__ = CryptContext(
            schemes=["bcrypt"],
            deprecated="auto")

    def verify_password(self,plain_text_password:str, hashed_password:str):
        return self.__pwd_context__.verify(plain_text_password,hashed_password)

    def hash_password(self,password:str):
        return self.__pwd_context__.hash(password)
    
    async def create_user_tokens(self, user:User)->tuple[str,str]:
        payload = TokenPayload(name=user.name,user_id=str(user.id))
        access_token = self.__create_bearer_token(
            user_id=user.id,
            data=payload.__dict__,
            expire_hours=self.__ACCESS_TOKEN_EXPIRE_HOURS__)
        refresh_token = await self.__create_refresh_token(str(user.id))
        return (access_token, refresh_token)
        
    async def get_new_user_tokens(self,
        refresh_token:str) -> Result[tuple[str, str]]:
        result = self.__decode_jwt_refresh_token(refresh_token)
        if not result.status:
            return Result(status=False, exception=result.exception, data=None)
        
        token_payload = result.data
        is_valid = await self.__check_if_refresh_token_is_valid(token_payload)
        if not is_valid:
            return Result(status=False, data=None, exception=Unauthorized())
        
        user = await self.__user_repository.read_user_by_id(token_payload.user)
        payload = TokenPayload(name=user.name,user_id=str(user.id))
        new_access_token = self.__create_bearer_token(
            user_id=token_payload.user,
            data=payload.__dict__,
            expire_hours=self.__ACCESS_TOKEN_EXPIRE_HOURS__)

        return Result(status=True, data=(new_access_token, refresh_token), exception=None)
\end{verbatim}

The methods \texttt{\_\_create\_bearer\_token} and \texttt{\_\_decode\_token} are auxiliary functions used to create, decode, and verify tokens, respectively.

\begin{verbatim}
def __create_bearer_token(self,user_id:int, data:dict, expire_hours):
    data_to_enconde = data.copy()
    expire = datetime.now()+timedelta(hours=expire_hours)
    data_to_enconde["exp"] = expire
    data_to_enconde["sub"] = str(user_id)
    return jwt.encode(
        claims=data_to_enconde,
        key=self.__SECRET_KEY__,
        algorithm=self.__ALGORITHM__)

def __decode_token(self,token:str)->dict:
    return jwt.decode(
        token,
        key=self.__SECRET_KEY__,
        algorithms=self.__ALGORITHM__)
    
\end{verbatim}

\subsubsection{WebSocket}\label{subsubsec:WebSocketImplement}
The implementation of the connection via WebSocket was done using the \texttt{socket.io} library \cite{socketIoDocs}, which has various ready-to-use features that facilitate the management of Web Socket connections, such as the creation of rooms for firing notifications.

The structure adopted for managing Web Socket connections was designed in such a way that the client must make a websocket request to the root \textit{endpoint} of the \gls{API} to be registered in a specific virtual room. After token validation and successful completion of this request, the client begins to receive all messages directed to the room in which it was registered.

The current implementation contemplates only one room, specifically intended for sending notifications related to the operation of the machines. This room is identified by the identifier \texttt{NOTIFICATION\_ROOM}. This constant stores the value "\texttt{Notification}", which is the name of the room to be connected, stored along with the system constants described in \ref{subsubsec:constantes}.

The asynchronous mode \gls{ASGI} selected for the server creation, and the allowed origins for \textit{CORS} are set as empty.

\begin{verbatim}
socket_io_server = AsyncServer(async_mode="asgi",
    cors_allowed_origins=[])

socketio_app = ASGIApp(socketio_server=socket_io_server,
    socketio_path="")

socket_dispacher = WebSocketDispatcher(socket_io_server)

@socket_io_server.event
async def connect(sid, environ, auth):
    token = auth["Authorization"]
    await auth_middleware(token)
    socket_io_server.enter_room(sid, NOTIFICATION_ROOM)
\end{verbatim}

The \texttt{socket\_io\_server} object is responsible for managing the \textit{WebSocket} communication, while the \texttt{socketio\_app} creates an \gls{ASGI} application that interacts with the \textit{WebSocket} server, and is added to the FastAPI server. Additionally, an instance of the \texttt{WebSocketDispatcher} class was created to facilitate the sending of notifications through the \textit{WebSocket}. This configuration is done at system initialization, explained in \ref{subsec:main}

In the connection event, named \texttt{connect}, a client is automatically added to the \texttt{NOTIFICATION\_ROOM}.

Finally, the \texttt{WebSocketDispatcher} class has a \texttt{send\_notification} method, which is used to send notifications. When calling this method, the notification is converted to the JSON format and sent to all clients in the \texttt{NOTIFICATION\_ROOM} through the \texttt{emit} method.

\begin{verbatim}
class WebSocketDispatcher:
    def __init__(self,socket_io_server: AsyncServer):
        self.__socket_io_server = socket_io_server
    
    async def send_notification(self,
        machine_sensor_notification:MachinesSensorAlert):
        machine_sensors_dict = machine_sensor_notification.to_json()
        await self.__socket_io_server.emit(
            NOTIFICATION_ROOM,
            machine_sensors_dict,
            room=NOTIFICATION_ROOM)
\end{verbatim}

The \texttt{WebSocketDispatcher} class is used by the data receiving module, detailed in ~\ref{subsec:checkDataReceived}, to trigger notifications when an improper operation of the machines is identified.

\subsubsection{Thread Management for Asynchronous Tasks}\label{subsubsec:ThreadManager}
In the system architecture, the need to perform tasks concurrently, without blocking the execution of the \gls{API}, was identified. These tasks are the execution of the data reception module, and the checking of the system's metadata. Both tasks must be executed in parallel with the execution of the \gls{API}, without influencing its execution. Therefore, to achieve this goal, a thread manager, called \texttt{ThreadManager}, was implemented.

The \texttt{ThreadManager} class is designed following the Singleton pattern, ensuring that only one instance is created, thus avoiding conflicts or redundancies in thread management. A list called \texttt{threads} is initialized to store all created threads, while an asynchronous event loop, assigned to the \texttt{loop} variable, is created using the \texttt{asyncio} library \cite{pythonAsyncio}.

The \texttt{start\_async\_thread} method was introduced to facilitate the creation and management of asynchronous tasks. This method accepts an asynchronous function, \texttt{func}, as an argument and performs the following operations:

\begin{enumerate}
    \item An internal function \texttt{start\_function} is defined. This function is responsible for starting the execution of the asynchronous task.
    \item Within \texttt{start\_function}, the boolean variable \texttt{isSeted} is checked to determine if the event loop has already been set up. Otherwise, the event loop is set up and the asynchronous task is executed until completion through the \texttt{run\_until\_complete} method.
    \item If the event loop is already set up (\texttt{isSeted = True}), the asynchronous task is simply added to the existing loop using \texttt{create\_task}.
    \item Finally, a new thread is created with \texttt{start\_function} as the target and added to the \texttt{threads} list. The thread is then started, executing the asynchronous task.
\end{enumerate}

\begin{verbatim}
import asyncio
from threading import Thread

class ThreadManager(metaclass=Singleton):
    def __init__(self):
        self.threads = []
        self.loop = asyncio.new_event_loop()
        self.isSeted = False

    def start_async_thread(self,func):
        def start_function():
            if not self.isSeted:
                asyncio.set_event_loop(self.loop)
                self.isSeted = True
                self.loop.run_until_complete(func())
            else:
                self.loop.create_task(func())

        new_thread = Thread(target = start_function)
        self.threads.append(new_thread)
        new_thread.start()
\end{verbatim}

This implementation allows the execution of multiple asynchronous tasks in parallel, each in its own thread, all managed by the same asynchronous event loop.

\subsubsection{Database}\label{subsubsec:DatabaseImpl}
In the process of implementing the system, to establish an efficient connection with the database, the \texttt{motor} library \cite{motorDocs} was adopted as the mechanism.

At the heart of the connection strategy is a base class, named \texttt{BaseDB}, which is responsible not only for establishing the connection with MongoDB, but also for defining a series of basic operations for the manipulation of stored data. The structure of this class is presented below:

\begin{verbatim}
import motor
class BaseDB:
    def __init__(self):
        self.client = motor.motor_tornado.MotorClient(url, port)
\end{verbatim}

Some of the fundamental operations implemented by \texttt{BaseDB} include:

\begin{itemize}
    \item \texttt{insert\_one}: Receives as parameters the corresponding \textit{database} and \textit{collection} in text format, and the \textit{data} to be inserted. It inserts a document into the specified collection.
    
    \item \texttt{insert\_many}: Receives as parameters the corresponding \textit{database} and \textit{collection} in text format, and the \textit{data} containing several documents to be inserted. It inserts several documents into the specified collection.

    \item \texttt{read\_data\_with\_pagination}: Receives as parameters the \textit{database}, the \textit{collection}, the \textit{query}, the \textit{page\_number}, the \textit{limit}, the \textit{sort\_descending\_field}, and the \textit{projection}. Retrieves data with pagination, allowing for a more organized reading.
    
    \item \texttt{read\_data\_with\_limit}: Receives as parameters the \textit{database}, the \textit{collection}, the \textit{query}, and the \textit{limit}. Reads data with a predefined limit of returned documents.
    
    \item \texttt{read\_data}: Receives as parameters the \textit{database}, the \textit{collection}, and the \textit{query}. Performs a simple data reading based on a query.
    
    \item \texttt{get\_distinct\_property}: Receives as parameters the \textit{database}, the \textit{collection}, and the \textit{property}. It obtains distinct properties from a collection, checking all the present documents.
    
    \item \texttt{list\_collections\_by\_db}: Receives as a parameter the \textit{database}. It lists all the collections present in a specific database.
    
    \item \texttt{add\_item\_into\_lists\_by\_filter}: Receives as parameters the \textit{database}, the \textit{collection}, the \textit{filter}, the \textit{list\_properties}, and the \textit{new\_data}. It adds an item into specific lists based on a filter.
    
    \item \texttt{update\_item}: Receives as parameters the \textit{database}, the \textit{collection}, the \textit{data} to be updated, and the \textit{filter}. It updates a specific document.
    
    \item \texttt{update\_many\_items}: Receives as parameters the \textit{database}, the \textit{collection}, the \textit{data} to be updated, and the \textit{filter}. It updates several documents that meet a filter.
    
    \item \texttt{count\_documents}: Receives as parameters the \textit{database}, the \textit{collection}, and the \textit{query}. It counts the number of documents in a collection that meet a query.
    
    \item \texttt{get\_data\_between\_dates}: Receives as parameters the \textit{database}, the \textit{collection}, and the \textit{query}. Retrieves data between two specific dates.
\end{itemize}

With the access base established, other classes were developed, inherited from \texttt{BaseDB}, to meet specific system contexts. These classes follow the singleton pattern, which ensures that only one instance of the connection is created for a specific context, optimizing resource management. An example is the \texttt{MongoDBIOT} class intended for the data reception module:

\begin{verbatim}
class MongoDBIOT(BaseDB, metaclass=Singleton):
    def __init__(self):
        super().__init__()
\end{verbatim}

Similar classes, following the same format, were created for other contexts, such as database access through the \gls{API}, ensuring an organized and efficient structure for connection and data manipulation.

\subsection{Common Files}\label{subsec:commum}

Within the structure of the \gls{API}, a folder named \texttt{common} was implemented with the aim of centralizing reusable components, covering multiple modules and layers. This organization was established to maximize development efficiency and code consistency.

\subsubsection{Data Models}\label{subsubsec:dataModel}
The data models section in the \texttt{common} folder houses various classes that define the structure of the used data. Classes specifying users and sensor data are present, and they make use of the \texttt{Pydantic} library to define the models and create data validations.

\texttt{Pydantic} \cite{pydanticDocs} is a data validation library that adds static typing in Python to validate that the received data matches a certain format or schema. When used for the construction of the \gls{API}, \texttt{Pydantic} contributes to the automatic and consistent verification of data sent through \gls{HTTP} requests, and manipulations performed in the database. This approach reduces the need for manual coding for data validations, thus speeding up development time and increasing code robustness.

To illustrate, we have the NotificationSensorResponse class, which is responsible for defining the data model that is returned when the \gls{API} receives a request for a specific user's notifications. The use of \texttt{BaseModel} in the inheritance system, from \texttt{Pydantic}, necessary to define the return types within FastAPI, is highlighted. In addition, the \texttt{Field} function, also from \texttt{Pydantic}, is used to indicate with three points that it is a mandatory attribute to be informed in the class construction.

\begin{verbatim}
class NotificationSensorResponse(BaseModel):
    data:list[dict] = Field(...)
    total_count:int = Field(...)
\end{verbatim}

Other important data models are the exception classes and a class called \texttt{Result}, responsible for data traffic between the different layers of the application, shown in the implementation of the \gls{API} module in \ref{subsec:modules}.
Example of a class that defines a system exception.

\begin{verbatim}
class CustomBaseException(Exception):
    def __init__(self, message:str, exception, *args: object) -> None:
        self.message = message,
        self.exception = exception
        super().__init__(*args)

class GenericException(CustomBaseException):
    def __init__(self,
        message:str =   "An error has occurred",
        exception = None) -> None:
        super().__init__(message, exception)
\end{verbatim}


Class \texttt{Result} used for communication between layers of the system modules. The \texttt{TypeVar} is used to indicate a generic type for the \texttt{data} attribute of the class.

\begin{verbatim}
from typing import TypeVar, Generic
from src.common.models.exceptions.unauthorized import CustomBaseException

T = TypeVar('T')
class Result(Generic[T]):
    def __init__(self, status:bool, data:T|None, exception:CustomBaseException|None):
        self.status = status
        self.data = data
        self.exception = exception
\end{verbatim}

The use of the \texttt{Singleton} class is also highlighted, used when there is a need to ensure that only one instance of a certain class will be used.

\begin{verbatim}
class Singleton(type):
    _instances = {}
    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)
        return cls._instances[cls]
\end{verbatim}

Finally, the \texttt{PyObjectId} class is highlighted, used to define a type for the ID attribute of classes that represent database models. The methods defined for this class are used internally by \texttt{FastAPI} and \texttt{Pydantic}.

This class is necessary so that the ID can be correctly converted to text, and returned in the requests. Furthermore, the use of this class enables the manipulation of the ID when necessary, leaving the management of unique identifiers to the application and not to the database.

\begin{verbatim}
class PyObjectId(ObjectId):
    @classmethod
    def __get_validators__(cls):
        yield cls.validate

    @classmethod
    def validate(cls, v):
        if not ObjectId.is_valid(v):
            raise ValueError("Invalid object id")
        return ObjectId(v)

    @classmethod
    def __modify_schema__(cls, field_schema):
        field_schema.update(type="string")
\end{verbatim}

\subsubsection{Helper Functions}\label{subsubsec:helpers}

The section of \textit{helper} functions in the \texttt{common} folder was built to contain methods that are common in different modules of the system, avoiding code duplication and standardizing operation.

An example of these functions is the conversion of \texttt{Datatype}, shown in the section on constants \ref{subsubsec:constantes}, to MongoDB collections. The following code illustrates one of these processes:

\begin{verbatim}
def sensor_name_to_processed_collection(
    sensor_name:Datatype)->str:
    sensor = (sensor_name.name).capitalize()
    return IOT_AGGREGATION_COLLECTION.replace("NAME", sensor)
\end{verbatim}

These functions are used to determine the correct names of the collections according to the type of data to be processed and manipulated by the modules. Functions such as \texttt{sensor\_name\_to\_processed\_collection} and \texttt{sensor\_name\_to\_raw\_data\_collection} convert between sensor names and collection names.

Additionally, a series of functions was developed to map the processed collection name back to the corresponding \texttt{Datatype}, shown in the section on constants \ref{subsubsec:constantes}, ensuring safer and more consistent data manipulation.

\subsubsection{Constants}\label{subsubsec:constantes}
Finally, the constants section stores a series of fixed values that are used in various parts of the system. This includes database names, alert types, websocket rooms, and others as needed.

Among the constants, \texttt{DataType} stands out, which is an enum that standardizes the types of data that can be received from the sensors. This standardization is employed in various modules to ensure that data is received, processed, stored, and returned in a consistent and correct manner.

\begin{verbatim}
from enum import Enum

class Datatype(Enum):
    PRESSURE = "PRESSURE"
    TEMPERATURE = "TEMPERATURE"
    VOLTAGE = "VOLTAGE"
    CURRENT = "CURRENT"
    SPEED = "SPEED"
    ACCELERATION = "ACCELERATION"
    DISTANCE = "DISTANCE"
    HUMIDITY = "HUMIDITY"
    FORCE = "FORCE"
    PRODUCTION_COUNTER = "PRODUCTION_COUNTER"
\end{verbatim}

\subsection{Modules}\label{subsec:modules}
The \gls{API} was structured into modules, each one responsible for managing a certain context. The developed modules are listed below.

\begin{enumerate}
    \item \textbf{IOT Analytics}: Module responsible for managing access to sensor information, both real-time data via stream, and the information processed by the data processing module, explained in ~\ref{sec:ImplModuloProcessamento}.
    \item \textbf{Notifications}: Module responsible for managing access to notifications.
    \item \textbf{User}: Module responsible for managing the system users' information, and performing the authentication explained in ~\ref{subsubsec:auth}.
    \item \textbf{Downtime Analytics}: Module used to provide test data on machine downtime. This module feeds the screen that displays information about machine downtime.
\end{enumerate}

Each module followed a pattern of having one layer for receiving \gls{HTTP} requests, the \texttt{controller}, another to handle the request according to business rules, the \texttt{service}, and the \texttt{repository}, to provide methods for accessing and manipulating information in the database.

\subsubsection{Controller}\label{subsubsec:controller}
The controller has the function of receiving \gls{HTTP} requests, sending the received information to the service layer, and making the appropriate return, with the formatted information, and correct \gls{HTTP} code.

To exemplify the operation of the controller, a specific example will be presented. The following code snippet represents the router of the \gls{API} for the \gls{IoT} sensor data:

\begin{verbatim}
iot_data_router = APIRouter(tags=["IOT Data"], dependencies=[Depends(auth_middleware)])

service = ServiceIOT()

@iot_data_router.get("/realtime")
async def real_time_iot(): 
    def get_real_time_data():
        sensor = SensorValue()
        while True:
            time.sleep(1)
            lista_json = [machine.to_json() for machine in sensor.machine_list]
            last_data = json.dumps(lista_json)
            yield bytes(last_data, "utf-8")

    return StreamingResponse(
        get_real_time_data(),
        media_type="application/octet-stream")
\end{verbatim}

In this example, the controller uses the \texttt{APIRouter} to create routes associated with IoT data. An authentication middleware is applied as a dependency, as shown in the authentication detail in \ref{subsubsec:auth}, ensuring that only authenticated users can access these routes. In this case, by applying the middleware in the creation of the \texttt{iot\_data\_router}, it is guaranteed that all \texttt{endpoints} created from it require authentication.

Below, an instance of the service to be used by the \texttt{endpoints} to respond to the received requests is created.

The \texttt{/realtime} route is designated to provide real-time data. An internal function, \texttt{get\_real\_time\_data}, is responsible for collecting this data from the \texttt{SensorValue}, explained in \ref{sec:Implementation of the data reception module}. In this endpoint, the \gls{API} takes the current values and returns a \texttt{StreamingResponse}, which sends real-time data as a continuous stream.

The other routes, such as \texttt{/machines\_in\_sensor} and \texttt{/graph\_info}, operate in a similar way, but with different responsibilities. They make calls to the \texttt{ServiceIOT} instance to retrieve specific information and return it to the client. If an exception or error occurs, an \texttt{HTTPException} is thrown with an appropriate HTTP status code and a detailed error message.

In these two endpoints, it is important to highlight the specification of the \texttt{response\_model}, so that automatic validations by the framework occur before the data is returned, ensuring consistency in the returned data.

\begin{verbatim}
@iot_data_router.get("/machines_in_sensor", response_model=list[MachinesSensor])
async def get_machines_in_sensor():
    result = await service.get_all_machines_processed_info()
    if result.status:
        return result.data
    
    raise HTTPException(status_code=500, detail=result.exception.message)

@iot_data_router.get("/graph_info", response_model=list[ProcessedData])

\begin{verbatim}
async def get_graph_info(machine:str, sensor:Datatype, initial_date:datetime, end_date:datetime):
    result = await service.get_processed_data(
        machine=machine,
        data_type=sensor,
        initial_date=initial_date,
        end_date=end_date)
    
    if result.status:
        return result.data
    
    raise HTTPException(status_code=500, detail=result.exception.message)
\end{verbatim}

\subsubsection{Service}\label{subsubsec:service}
The service layer is used to apply the appropriate rules before returning the data to the control layer ~\ref{subsubsec:controller}. It can access the repository layer to read or write data, and it should return the data to the control layer using the \texttt{Result} class, shown in section ~\ref{subsec:commum}, so that the result of the processing can be correctly identified, and the appropriate return can be given to the client who made the request.

For a deeper understanding, a specific example of the service layer implementation follows below:

\begin{verbatim}
class ServiceIOT:
    def __init__(self):
        self.__repository = RepositoryIOT()
        self.__database__ = MongoDB()
        self.appMetadata = MetadataRepository()
            
    async def get_processed_data(self,
        machine:str,
        data_type:Datatype,
        initial_date:datetime,
        end_date:datetime)-> Result[list[ProcessedData]]:
        try:
            alert_parameter = await self.appMetadata.get_sensor_alert_value(
            data_type)
            processed_data = await self.__repository.read_iot_processed_data__(
                machine=machine,
                datatype=data_type,
                initial_date=initial_date,
                end_date=end_date,
                sort_by_field="more_recent_register")
            
            for data in processed_data:
                data["alert_parameter"] = alert_parameter
            return Result[list[MachinesSensor]](
                status=True,
                data=processed_data,
                exception=None)
        except Exception as ex:
            return Result[list[MachinesSensor]](
                status=False,
                data=None,
                exception=GenericException(exception=ex))
\end{verbatim}

In this implementation, the \texttt{ServiceIOT} class is initialized with instances of \texttt{RepositoryIOT} and \texttt{MetadataRepository}, allowing the service to access the corresponding repository and metadata layers.

The \texttt{get\_processed\_data} method is used to obtain processed data based on various parameters such as machine, data type, and date range. Initially, an alert value is retrieved from the sensor metadata for the provided data type. Subsequently, the processed data is read from the repository. For each retrieved data entry, the alert value is added as a new field. The method returns a \texttt{Result} object encapsulating these data. The \texttt{Result} object is detailed in ~\ref{subsec:commum}.

The \texttt{get\_all\_machines\_processed\_info} method retrieves information about all processed machines and sensors. It iterates through the processed data collections, aggregating machine and sensor information. In case of success, it returns a \texttt{Result} object containing a list of machines and their corresponding sensors.

\begin{verbatim}
async def get_all_machines_processed_info(
    self)-> Result[list[MachinesSensor]]:
    try:
        collection_list = 
            await self.__repository.get_processed_data_collections()
        machine_sensors: list[MachinesSensor] = []
        for collection in collection_list:
            machine_list = await self.__repository
                .get_distinct_machines_by_collection(collection)
            sensor = processed_collection_to_sensor_name(collection)

            for machine in machine_list:
                matching_sensor = 
                next((data for data in machine_sensors 
                    if data.machine == machine), None)
                if matching_sensor:
                    matching_sensor.sensors.append(sensor)
                else:
                    machine_sensors.append(MachinesSensor(
                        machine=machine,
                        sensors=[sensor]))
        
        return Result[list[MachinesSensor]](
            status=True,
            data=machine_sensors,
            exception=None)
    except Exception as ex:
        print(ex)
        return Result[bool](
            status=False,
            data=None,
            exception=GenericException(exception=ex)) 
\end{verbatim}

The last method, \texttt{read\_raw\_data\_by\_id}, is used to read raw data based on an identifier and data type. It accesses the corresponding repository to retrieve the data and returns a \texttt{Result} object containing these data or an exception, if applicable.
\begin{verbatim}
async def read_raw_data_by_id(self,
    raw_data_id:str,
    datatype:Datatype) -> Result:
    try:
        collection = sensor_name_to_raw_data_collection(datatype)
        result = await self.__repository.read_raw_data(collection,raw_data_id)
        return Result(status=True, data=result, exception=None) 
    except Exception as ex:
        return Result[bool](
            status=False,
            data=None,
            exception=GenericException(exception=ex)) 

\end{verbatim}
This implementation exemplifies how the service layer interacts with the repository layers and accesses metadata, and how it prepares the data to be sent back to the controller, thus ensuring a cohesive and efficient data flow through the various layers of the application.

\subsubsection{Respository}\label{subsubsec:repository}
Finally, the repository layer is responsible for accessing the database and performing read and write operations as needed. This layer initiates a connection with the database, and its methods use the base methods defined by the database connection infrastructure, in ~\ref{subsubsec:DatabaseImpl}, to perform operations according to the context of that module.

The following code provides an example of the implementation of this layer:

\begin{verbatim}
class RepositoryIOT:
    def __init__(self):
        self.__database__ = MongoDB()
    
    async def get_processed_data_collections(self):
        collection_list = 
            await self.__database__.list_collections_by_db(
            IOT_PROCESSED_DATA)
    
        return collection_list
        
    async def get_distinct_machines_by_collection(self, collection:str):
        machine_list = 
            await self.__database__.get_distinct_property(
                IOT_PROCESSED_DATA,
                collection,
                "machine")

        return machine_list
    
    async def read_raw_data(self, collection:str, raw_data_id:str):
        result = await self.__database__.read_data(
            IOT_DATABASE,
            collection,
            {"_id":ObjectId(raw_data_id)})

        return result
    
    async def read_iot_processed_data__(self, machine:str, datatype:Datatype, 
        initial_date:datetime, end_date:datetime, 
        sort_by_field:str) -> list[ProcessedData]:
        
        try:
            collection = sensor_name_to_processed_collection(datatype)
            query = {
                "machine":machine,
                sort_by_field:{
                    "$gte":initial_date,
                    "$lte":end_date
                }
            }
            result = await self.__database__.get_data_between_dates(
                IOT_PROCESSED_DATA,
                collection,query)
            return result
        except Exception as ex:
            print(ex)
            raise ex
\end{verbatim}

Upon initializing the \texttt{RepositoryIOT} class, a connection with MongoDB is instantiated. The \texttt{get\_processed\_data\_collections} method is used to list all the processed data collections from the \texttt{IOT\_PROCESSED\_DATA} database. This method makes a direct call to the collection listing method provided by the \texttt{MongoDB} class.

The \texttt{get\_distinct\_machines\_by\_collection} method is responsible for retrieving a list of distinct machines for a given collection. It does this through the \texttt{get\_distinct\_property} method of the database.

The \texttt{read\_raw\_data} method is used to read raw data from a specific collection, using the data ID as a search parameter. It makes a call to the \texttt{read\_data} method of the \texttt{MongoDB} class, providing the necessary parameters for data reading.

Finally, the \texttt{read\_iot\_processed\_data\_\_} method is used to read processed data based on various criteria such as machine, data type, and date range. A query is built for this purpose and passed to the \texttt{get\_data\_between\_dates} method of the \texttt{MongoDB} class.

Each of these methods assists in maintaining a clear separation of responsibilities, allowing the service layer to maintain a strict focus on business logic, while the repository layer manages database operations.